{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phones labels:  ['sil', 's', 'ao', 'l', 'r', 'iy', 'vcl', 'd', 'eh', 'cl', 'p', 'ix', 'z', 'ih', 'sh', 'n', 'v', 'aa', 'y', 'uw', 'w', 'ey', 'dx', 'b', 'ay', 'ng', 'k', 'epi', 'ch', 'dh', 'er', 'en', 'g', 'aw', 'hh', 'ae', 'ow', 't', 'ax', 'm', 'zh', 'ah', 'el', 'f', 'jh', 'uh', 'oy', 'th']\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "from scipy.special import logsumexp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, (1, 5))\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 48)\n",
    "        self.sm = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(-1, 128)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.sm(x)\n",
    "        return x\n",
    "    \n",
    "def load_audio_to_melspec_tensor(wavpath, sample_rate=16000):\n",
    "    window_size = .025\n",
    "    window_stride = 0.01\n",
    "    n_dft = 512\n",
    "    win_length = int(sample_rate * window_size)\n",
    "    hop_length = int(sample_rate * window_stride)\n",
    "    y, sr = librosa.load(wavpath, sr=sample_rate)\n",
    "    y = y - y.mean()\n",
    "    y = np.append(y[0],y[1:]-.97*y[:-1])\n",
    "    # compute mel spectrogram\n",
    "    stft = librosa.stft(y, n_fft=n_dft, hop_length=hop_length,\n",
    "        win_length=win_length, window=scipy.signal.hamming)\n",
    "    spec = np.abs(stft)**2\n",
    "    mel_basis = librosa.filters.mel(sr=sample_rate, n_fft=n_dft, n_mels=40, fmin=20)\n",
    "    melspec = np.dot(mel_basis, spec)\n",
    "    logspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "    logspec = np.transpose(logspec)\n",
    "    logspec_tensor = torch.tensor(logspec)\n",
    "    return logspec_tensor\n",
    "\n",
    "def compute_phone_likelihoods(model, logspec):\n",
    "    likelihood_list = []\n",
    "    with torch.no_grad():\n",
    "        for j in range(6, logspec.size(0) - 5):\n",
    "            inp = logspec[j-5:j+6,:].unsqueeze(0)\n",
    "            output = model(inp) # output will be log probabilities over classes\n",
    "            output = output - math.log(1. / 48) # subtract the logprob of the class priors (assumed to be uniform)\n",
    "            likelihood_list.append(output[0])\n",
    "    likelihoods = torch.transpose(torch.stack(likelihood_list, dim=1), 0, 1).numpy()\n",
    "    return likelihoods\n",
    "\n",
    "model = MyNet()\n",
    "model.load_state_dict(torch.load('lab3_AM.pt'))\n",
    "\n",
    "lab3_data = np.load('lab3_phone_labels.npz')\n",
    "phone_labels = list(lab3_data['phone_labels'])\n",
    "print (\"phones labels: \", phone_labels)\n",
    "\n",
    "def phones2indices(phones):\n",
    "    return [phone_labels.index(p) for p in phones]\n",
    "\n",
    "\n",
    "# fee_HMM = MyHMM(phones2indices(['sil', 'f', 'iy', 'sil']), np.array([0.5, 0.5, 0, 0]), np.array([[.9,.1,0,0],[0,.9,.1,0],[0,0,.9,.1],[0,0,0,1]]))\n",
    "# pea_HMM = MyHMM(phones2indices(['sil', 'p', 'iy', 'sil']), np.array([0.5, 0.5, 0, 0]), np.array([[.9,.1,0,0],[0,.9,.1,0],[0,0,.9,.1],[0,0,0,1]]))\n",
    "# rock_HMM = MyHMM(phones2indices(['sil', 'r', 'aa', 'cl', 'k', 'sil']), np.array([0.5,0.5,0,0,0,0]), np.array([[.9,.1,0,0,0,0],[0,.9,.1,0,0,0],[0,0,.9,.1,0,0],[0,0,0,.9,.1,0],[0,0,0,0,.9,.1],[0,0,0,0,0,1]]))\n",
    "# burt_HMM = MyHMM(phones2indices(['sil', 'b', 'er', 'cl', 't', 'sil']), np.array([0.5,0.5,0,0,0,0]), np.array([[.9,.1,0,0,0,0],[0,.9,.1,0,0,0],[0,0,.9,.1,0,0],[0,0,0,.9,.1,0],[0,0,0,0,.9,.1],[0,0,0,0,0,1]]))\n",
    "# see_HMM = MyHMM(phones2indices(['sil', 's', 'iy', 'sil']), np.array([0.5, 0.5, 0, 0]), np.array([[.9,.1,0,0],[0,.9,.1,0],[0,0,.9,.1],[0,0,0,1]]))\n",
    "# she_HMM = MyHMM(phones2indices(['sil', 'sh', 'iy', 'sil']), np.array([0.5, 0.5, 0, 0]), np.array([[.9,.1,0,0],[0,.9,.1,0],[0,0,.9,.1],[0,0,0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burt_phone_likelihoods.shape:  (100, 48)\n",
      "fee_phone_likelihoods.shape:  (103, 48)\n",
      "pea_phone_likelihoods.shape:  (113, 48)\n",
      "rock_phone_likelihoods.shape:  (81, 48)\n",
      "see_phone_likelihoods.shape:  (96, 48)\n",
      "she_phone_likelihoods.shape:  (107, 48)\n"
     ]
    }
   ],
   "source": [
    "# load in audio files\n",
    "# convert to mel-logspec tensor\n",
    "# compute phone likelihoods for each\n",
    "\n",
    "burt_phone_likelihoods = compute_phone_likelihoods(model, load_audio_to_melspec_tensor(wavpath=\"burt.wav\"))\n",
    "fee_phone_likelihoods = compute_phone_likelihoods(model, load_audio_to_melspec_tensor(wavpath=\"fee.wav\"))\n",
    "pea_phone_likelihoods = compute_phone_likelihoods(model, load_audio_to_melspec_tensor(wavpath=\"pea.wav\"))\n",
    "rock_phone_likelihoods = compute_phone_likelihoods(model, load_audio_to_melspec_tensor(wavpath=\"rock.wav\"))\n",
    "see_phone_likelihoods = compute_phone_likelihoods(model, load_audio_to_melspec_tensor(wavpath=\"see.wav\"))\n",
    "she_phone_likelihoods = compute_phone_likelihoods(model, load_audio_to_melspec_tensor(wavpath=\"she.wav\"))\n",
    "\n",
    "print (\"burt_phone_likelihoods.shape: \", burt_phone_likelihoods.shape)\n",
    "print (\"fee_phone_likelihoods.shape: \", fee_phone_likelihoods.shape)\n",
    "print (\"pea_phone_likelihoods.shape: \", pea_phone_likelihoods.shape)\n",
    "print (\"rock_phone_likelihoods.shape: \", rock_phone_likelihoods.shape)\n",
    "print (\"see_phone_likelihoods.shape: \", see_phone_likelihoods.shape)\n",
    "print (\"she_phone_likelihoods.shape: \", she_phone_likelihoods.shape)\n",
    "\n",
    "#np.set_printoptions(threshold=np.inf, suppress=True)\n",
    "#print (\"burt_phone_likelihoods: \", burt_phone_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement hidden markov model\n",
    "# A (N x N)= state transition distribution\n",
    "# pi (N x 1)= initial state distribution\n",
    "\n",
    "class MyHMM:\n",
    "    def __init__(self, state_labels, initial_state_distribution, transition_matrix, eps=1e-200):\n",
    "        self.eps = eps\n",
    "        self.N_total_states = len(state_labels)\n",
    "        # (the product of probabilities becomes addition in log space)\n",
    "        self.pi = np.log(initial_state_distribution + eps)\n",
    "        self.A = np.log(transition_matrix + eps) #A_{ji} is prob of transitioning from state j to state i\n",
    "        self.labels = state_labels # a list where self.labels[j] is the index of the phone label belonging to the jth state\n",
    "\n",
    "\n",
    "    def forward(self, state_likelihoods): # state_likelihoods.shape is assumed to be (T_timesteps, 48)\n",
    "        # create B array (T_total_timesteps, N_total_states)\n",
    "        T_total_timesteps = state_likelihoods.shape[0]\n",
    "        self.B = np.zeros((T_total_timesteps, self.N_total_states))\n",
    "        i = 0\n",
    "        for state in self.labels:\n",
    "            self.B[:, i] = state_likelihoods[:, state]\n",
    "            i += 1\n",
    "             \n",
    "        # create alpha matrix (T_total_timesteps, N_total_states)\n",
    "        alpha_matrix = np.zeros((T_total_timesteps, self.N_total_states))\n",
    "        \n",
    "        # initialization\n",
    "        t = 0 # time step\n",
    "        i = 0 # state \n",
    "        for i in range (self.N_total_states):\n",
    "            alpha_matrix[t, i] = np.add(self.B[t, i], self.pi[i])\n",
    "        \n",
    "        # induction step\n",
    "        for t in range(0, T_total_timesteps - 1):\n",
    "            for i in range (self.N_total_states):\n",
    "                sum_array = []\n",
    "                # get sum\n",
    "                for j in range(self.N_total_states):\n",
    "                    sum_array.append(np.add(alpha_matrix[t, j], self.A[j, i]))\n",
    "                # multiply values and set alpha matrix\n",
    "                value = np.add(logsumexp(sum_array), self.B[t + 1, i])\n",
    "                alpha_matrix[t + 1, i] = value\n",
    "\n",
    "        # termination\n",
    "        return alpha_matrix[T_total_timesteps - 1, self.N_total_states - 1]\n",
    "    \n",
    "\n",
    "    def viterbi(self, state_likelihoods): # state_likelihoods.shape is assumed to be (T_timesteps, 48)\n",
    "        # create B array\n",
    "        T_total_timesteps = state_likelihoods.shape[0]\n",
    "        self.B = np.zeros((T_total_timesteps, self.N_total_states))\n",
    "        i = 0\n",
    "        for state in self.labels:\n",
    "            self.B[:,i] = state_likelihoods[:,state]\n",
    "            i += 1\n",
    "\n",
    "        # create psi matrix (backtrace)\n",
    "        psi_matrix = np.zeros((T_total_timesteps, self.N_total_states), dtype=np.int8)\n",
    "        for i in range(self.N_total_states):\n",
    "            psi_matrix[0, i] = 0\n",
    "        \n",
    "        # create delta array (T_total_timesteps, N_total_states)\n",
    "        delta_matrix = np.zeros((T_total_timesteps, self.N_total_states))\n",
    "\n",
    "        # initialization\n",
    "        t = 0 # time step\n",
    "        i = 0 # state \n",
    "        for i in range (self.N_total_states):\n",
    "            delta_matrix[t, i] = np.add(self.B[t, i], self.pi[i])\n",
    "\n",
    "        # induction step\n",
    "        for t in range(1, T_total_timesteps):\n",
    "            for i in range (self.N_total_states):\n",
    "                find_max_array = []\n",
    "                # get induction values to find max\n",
    "                for j in range(self.N_total_states):\n",
    "                    find_max_array.append(np.add(delta_matrix[t - 1, j], self.A[j, i]))\n",
    "                # find max, multiply values, and set delta matrix\n",
    "                max = np.max(find_max_array)\n",
    "                value = np.add(max, self.B[t, i])\n",
    "                delta_matrix[t, i] = value\n",
    "                # set psi backtrace value\n",
    "                psi_matrix[t, i] = int(np.argmax(find_max_array))\n",
    "\n",
    "        # termination\n",
    "        output_path = []\n",
    "        t = T_total_timesteps - 1\n",
    "        q = int(np.argmax(delta_matrix[t,:]))\n",
    "        output_path.append(q)\n",
    "        t -= 1\n",
    "        while t >= 0:\n",
    "            q = int(psi_matrix[t + 1, int(q)])\n",
    "            output_path.append(q)\n",
    "            t -= 1\n",
    "    \n",
    "        output_path.reverse()\n",
    "        return output_path\n",
    "    \n",
    "    \n",
    "    def viterbi_transition_update(self, state_likelihoods): # state_likelihoods.shape is assumed to be (T_timesteps, 48)\n",
    "        # compute viterbi algorithm\n",
    "        viterbi_states = self.viterbi(state_likelihoods)\n",
    "\n",
    "        # create temp A matrix using viterbi output\n",
    "        temp_A_matrix = np.zeros((self.N_total_states, self.N_total_states))\n",
    "        # number of times model made transition out of state i\n",
    "        num_out_states = np.zeros(self.N_total_states)\n",
    "        t = 0\n",
    "        for t in range(len(viterbi_states) - 1):\n",
    "            state_i = viterbi_states[t]\n",
    "            state_j = viterbi_states[t + 1]\n",
    "            # number of times transition was made from state i to state j\n",
    "            temp_A_matrix[state_i, state_j] += 1\n",
    "            # number of times model made transition out of state i\n",
    "            num_out_states[state_i] += 1\n",
    "\n",
    "        # compute log probabilities for A matrix\n",
    "        for i in range(self.N_total_states):\n",
    "            for j in range (self.N_total_states):\n",
    "                numerator = temp_A_matrix[i, j]\n",
    "                denominator = num_out_states[i]\n",
    "                self.A[i, j] = np.log((numerator / denominator) + self.eps)\n",
    "\n",
    "        #print (\"A log matrix: \", self.A)\n",
    "        #print (\"A matrix: \",np.exp(self.A))\n",
    "        #print (\"viterbi states: \", viterbi_states)\n",
    "        return self.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -0.04255961,   -3.17805383, -460.5170186 , -460.5170186 ],\n",
       "       [-460.5170186 ,   -0.04445176,   -3.13549422, -460.5170186 ],\n",
       "       [-460.5170186 , -460.5170186 ,   -0.03278982,   -3.4339872 ],\n",
       "       [-460.5170186 , -460.5170186 , -460.5170186 ,    0.        ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HMM inputs: (state_labels, initial_state_distribution (pi), transition_matrix (A), eps = 1e-200)\n",
    "# HMM.forward inputs: (state_likelihoods (B))\n",
    "# HMM.viterbi inputs: (state_likelihoods (B))\n",
    "# HMM.viterbi_transition_update inputs: (state_likelihoods (B))\n",
    "\n",
    "# create HMMs for each word\n",
    "burt_HMM = MyHMM(phones2indices(['sil', 'b', 'er', 'cl', 't', 'sil']), # state_labels\n",
    "                 np.array([0.5, 0.5, 0.0, 0.0, 0.0, 0.0]), # initial_state_distribution (pi)\n",
    "                 np.array([[0.9, 0.1, 0.0, 0.0, 0.0, 0.0], # transition_matrix (A)\n",
    "                           [0.0, 0.9, 0.1, 0.0, 0.0, 0.0],\n",
    "                           [0.0, 0.0, 0.9, 0.1, 0.0, 0.0],\n",
    "                           [0.0, 0.0, 0.0, 0.9, 0.1, 0.0],\n",
    "                           [0.0, 0.0, 0.0, 0.0, 0.9, 0.1],\n",
    "                           [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "fee_HMM = MyHMM(phones2indices(['sil', 'f', 'iy', 'sil']), \n",
    "                np.array([0.5, 0.5, 0.0, 0.0]), \n",
    "                np.array([[0.9, 0.1, 0.0, 0.0],\n",
    "                          [0.0, 0.9, 0.1, 0.0],\n",
    "                          [0.0, 0.0, 0.9, 0.1],\n",
    "                          [0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "pea_HMM = MyHMM(phones2indices(['sil', 'p', 'iy', 'sil']),  \n",
    "                np.array([0.5, 0.5, 0.0, 0.0]), \n",
    "                np.array([[0.9, 0.1, 0.0, 0.0],\n",
    "                          [0.0, 0.9, 0.1, 0.0],\n",
    "                          [0.0, 0.0, 0.9, 0.1],\n",
    "                          [0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "rock_HMM = MyHMM(phones2indices(['sil', 'r', 'aa', 'cl', 'k', 'sil']), \n",
    "                 np.array([0.5, 0.5, 0.0, 0.0, 0.0, 0.0]), \n",
    "                 np.array([[0.9, 0.1, 0.0, 0.0, 0.0, 0.0],\n",
    "                           [0.0, 0.9, 0.1, 0.0, 0.0, 0.0],\n",
    "                           [0.0, 0.0, 0.9, 0.1, 0.0, 0.0],\n",
    "                           [0.0, 0.0, 0.0, 0.9, 0.1, 0.0],\n",
    "                           [0.0, 0.0, 0.0, 0.0, 0.9, 0.1],\n",
    "                           [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "see_HMM = MyHMM(phones2indices(['sil', 's', 'iy', 'sil']), \n",
    "                np.array([0.5, 0.5, 0.0, 0.0]), \n",
    "                np.array([[0.9, 0.1, 0.0, 0.0],\n",
    "                          [0.0, 0.9, 0.1, 0.0],\n",
    "                          [0.0, 0.0, 0.9, 0.1],\n",
    "                          [0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "she_HMM = MyHMM(phones2indices(['sil', 'sh', 'iy', 'sil']), \n",
    "                np.array([0.5, 0.5, 0.0, 0.0]), \n",
    "                np.array([[0.9, 0.1, 0.0, 0.0],\n",
    "                          [0.0, 0.9, 0.1, 0.0],\n",
    "                          [0.0, 0.0, 0.9, 0.1],\n",
    "                          [0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "# update HMM transition matricies using respective phone likelihoods\n",
    "burt_HMM.viterbi_transition_update(burt_phone_likelihoods)\n",
    "fee_HMM.viterbi_transition_update(fee_phone_likelihoods)\n",
    "pea_HMM.viterbi_transition_update(pea_phone_likelihoods)\n",
    "rock_HMM.viterbi_transition_update(rock_phone_likelihoods)\n",
    "see_HMM.viterbi_transition_update(see_phone_likelihoods)\n",
    "she_HMM.viterbi_transition_update(she_phone_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- BURT --------\n",
      "> burtHMM | burt.wav:  219.9552471998736\n",
      "  burtHMM | fee.wav:  -85.011141227393\n",
      "  burtHMM | pea.wav:  76.81512053038593\n",
      "  burtHMM | rock.wav:  65.11156538607203\n",
      "  burtHMM | see.wav:  -152.63558949732385\n",
      "  burtHMM | she.wav:  -188.11785018464357\n",
      "-------- FEE --------\n",
      "  feeHMM | burt.wav:  -60.166692792513146\n",
      "> feeHMM | fee.wav:  215.34999565406088\n",
      "  feeHMM | pea.wav:  254.8044408537845\n",
      "  feeHMM | rock.wav:  -62.829131890032585\n",
      "  feeHMM | see.wav:  78.48275108614092\n",
      "  feeHMM | she.wav:  79.44591260902136\n",
      "-------- PEA --------\n",
      "  peaHMM | burt.wav:  -17.220309199742225\n",
      "  peaHMM | fee.wav:  182.86573358557777\n",
      "> peaHMM | pea.wav:  274.0872481035399\n",
      "  peaHMM | rock.wav:  -7.896217024177119\n",
      "  peaHMM | see.wav:  81.99344362391334\n",
      "  peaHMM | she.wav:  89.80794799046987\n",
      "-------- ROCK --------\n",
      "  rockHMM | burt.wav:  114.7559636625836\n",
      "  rockHMM | fee.wav:  -92.2072500128701\n",
      "  rockHMM | pea.wav:  14.371269978931451\n",
      "> rockHMM | rock.wav:  157.20291086481836\n",
      "  rockHMM | see.wav:  -171.33956695460665\n",
      "  rockHMM | she.wav:  -208.65438175542928\n",
      "-------- SEE --------\n",
      "  seeHMM | burt.wav:  -68.84685179021024\n",
      "  seeHMM | fee.wav:  191.4203989800937\n",
      "  seeHMM | pea.wav:  241.5428593584662\n",
      "  seeHMM | rock.wav:  -61.326416457221285\n",
      "> seeHMM | see.wav:  235.9318799826532\n",
      "  seeHMM | she.wav:  126.31835974642229\n",
      "-------- SHE --------\n",
      "  sheHMM | burt.wav:  -93.57788591023655\n",
      "  sheHMM | fee.wav:  192.04376335498532\n",
      "  sheHMM | pea.wav:  239.83977627180013\n",
      "  sheHMM | rock.wav:  -63.343695138325316\n",
      "  sheHMM | see.wav:  134.25410611354647\n",
      "> sheHMM | she.wav:  286.0632118090349\n"
     ]
    }
   ],
   "source": [
    "# remove scientific notation from prints\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# compute log likelihoods for all 6 waveforms with all 6 of the word HMMs\n",
    "# -------- BURT --------\n",
    "print (\"-------- BURT --------\")\n",
    "burtHMM_burtWORD    = burt_HMM.forward(burt_phone_likelihoods)\n",
    "burtHMM_feeWORD     = burt_HMM.forward(fee_phone_likelihoods)\n",
    "burtHMM_peaWORD     = burt_HMM.forward(pea_phone_likelihoods)\n",
    "burtHMM_rockWORD    = burt_HMM.forward(rock_phone_likelihoods)\n",
    "burtHMM_seeWORD     = burt_HMM.forward(see_phone_likelihoods)\n",
    "burtHMM_sheWORD     = burt_HMM.forward(she_phone_likelihoods)\n",
    "\n",
    "print (\"> burtHMM | burt.wav: \",  burtHMM_burtWORD)\n",
    "print (\"  burtHMM | fee.wav: \",   burtHMM_feeWORD)\n",
    "print (\"  burtHMM | pea.wav: \",   burtHMM_peaWORD)\n",
    "print (\"  burtHMM | rock.wav: \",  burtHMM_rockWORD)\n",
    "print (\"  burtHMM | see.wav: \",   burtHMM_seeWORD)\n",
    "print (\"  burtHMM | she.wav: \",   burtHMM_sheWORD)\n",
    "\n",
    "# -------- FEE --------\n",
    "print (\"-------- FEE --------\")\n",
    "feeHMM_burtWORD     = fee_HMM.forward(burt_phone_likelihoods)\n",
    "feeHMM_feeWORD      = fee_HMM.forward(fee_phone_likelihoods)\n",
    "feeHMM_peaWORD      = fee_HMM.forward(pea_phone_likelihoods)\n",
    "feeHMM_rockWORD     = fee_HMM.forward(rock_phone_likelihoods)\n",
    "feeHMM_seeWORD      = fee_HMM.forward(see_phone_likelihoods)\n",
    "feeHMM_sheWORD      = fee_HMM.forward(she_phone_likelihoods)\n",
    "\n",
    "print (\"  feeHMM | burt.wav: \",   feeHMM_burtWORD)\n",
    "print (\"> feeHMM | fee.wav: \",    feeHMM_feeWORD)\n",
    "print (\"  feeHMM | pea.wav: \",    feeHMM_peaWORD)\n",
    "print (\"  feeHMM | rock.wav: \",   feeHMM_rockWORD)\n",
    "print (\"  feeHMM | see.wav: \",    feeHMM_seeWORD)\n",
    "print (\"  feeHMM | she.wav: \",    feeHMM_sheWORD)\n",
    "\n",
    "# -------- PEA --------\n",
    "print (\"-------- PEA --------\")\n",
    "peaHMM_burtWORD     = pea_HMM.forward(burt_phone_likelihoods)\n",
    "peaHMM_feeWORD      = pea_HMM.forward(fee_phone_likelihoods)\n",
    "peaHMM_peaWORD      = pea_HMM.forward(pea_phone_likelihoods)\n",
    "peaHMM_rockWORD     = pea_HMM.forward(rock_phone_likelihoods)\n",
    "peaHMM_seeWORD      = pea_HMM.forward(see_phone_likelihoods)\n",
    "peaHMM_sheWORD      = pea_HMM.forward(she_phone_likelihoods)\n",
    "\n",
    "print (\"  peaHMM | burt.wav: \",   peaHMM_burtWORD)\n",
    "print (\"  peaHMM | fee.wav: \",    peaHMM_feeWORD)\n",
    "print (\"> peaHMM | pea.wav: \",    peaHMM_peaWORD)\n",
    "print (\"  peaHMM | rock.wav: \",   peaHMM_rockWORD)\n",
    "print (\"  peaHMM | see.wav: \",    peaHMM_seeWORD)\n",
    "print (\"  peaHMM | she.wav: \",    peaHMM_sheWORD)\n",
    "\n",
    "# -------- ROCK --------\n",
    "print (\"-------- ROCK --------\")\n",
    "rockHMM_burtWORD     = rock_HMM.forward(burt_phone_likelihoods)\n",
    "rockHMM_feeWORD      = rock_HMM.forward(fee_phone_likelihoods)\n",
    "rockHMM_peaWORD      = rock_HMM.forward(pea_phone_likelihoods)\n",
    "rockHMM_rockWORD     = rock_HMM.forward(rock_phone_likelihoods)\n",
    "rockHMM_seeWORD      = rock_HMM.forward(see_phone_likelihoods)\n",
    "rockHMM_sheWORD      = rock_HMM.forward(she_phone_likelihoods)\n",
    "\n",
    "print (\"  rockHMM | burt.wav: \",   rockHMM_burtWORD)\n",
    "print (\"  rockHMM | fee.wav: \",    rockHMM_feeWORD)\n",
    "print (\"  rockHMM | pea.wav: \",    rockHMM_peaWORD)\n",
    "print (\"> rockHMM | rock.wav: \",   rockHMM_rockWORD)\n",
    "print (\"  rockHMM | see.wav: \",    rockHMM_seeWORD)\n",
    "print (\"  rockHMM | she.wav: \",    rockHMM_sheWORD)\n",
    "\n",
    "# -------- SEE --------\n",
    "print (\"-------- SEE --------\")\n",
    "seeHMM_burtWORD     = see_HMM.forward(burt_phone_likelihoods)\n",
    "seeHMM_feeWORD      = see_HMM.forward(fee_phone_likelihoods)\n",
    "seeHMM_peaWORD      = see_HMM.forward(pea_phone_likelihoods)\n",
    "seeHMM_rockWORD     = see_HMM.forward(rock_phone_likelihoods)\n",
    "seeHMM_seeWORD      = see_HMM.forward(see_phone_likelihoods)\n",
    "seeHMM_sheWORD      = see_HMM.forward(she_phone_likelihoods)\n",
    "\n",
    "print (\"  seeHMM | burt.wav: \",   seeHMM_burtWORD)\n",
    "print (\"  seeHMM | fee.wav: \",    seeHMM_feeWORD)\n",
    "print (\"  seeHMM | pea.wav: \",    seeHMM_peaWORD)\n",
    "print (\"  seeHMM | rock.wav: \",   seeHMM_rockWORD)\n",
    "print (\"> seeHMM | see.wav: \",    seeHMM_seeWORD)\n",
    "print (\"  seeHMM | she.wav: \",    seeHMM_sheWORD)\n",
    "\n",
    "# -------- SHE --------\n",
    "print (\"-------- SHE --------\")\n",
    "sheHMM_burtWORD     = she_HMM.forward(burt_phone_likelihoods)\n",
    "sheHMM_feeWORD      = she_HMM.forward(fee_phone_likelihoods)\n",
    "sheHMM_peaWORD      = she_HMM.forward(pea_phone_likelihoods)\n",
    "sheHMM_rockWORD     = she_HMM.forward(rock_phone_likelihoods)\n",
    "sheHMM_seeWORD      = she_HMM.forward(see_phone_likelihoods)\n",
    "sheHMM_sheWORD      = she_HMM.forward(she_phone_likelihoods)\n",
    "\n",
    "print (\"  sheHMM | burt.wav: \",   sheHMM_burtWORD)\n",
    "print (\"  sheHMM | fee.wav: \",    sheHMM_feeWORD)\n",
    "print (\"  sheHMM | pea.wav: \",    sheHMM_peaWORD)\n",
    "print (\"  sheHMM | rock.wav: \",   sheHMM_rockWORD)\n",
    "print (\"  sheHMM | see.wav: \",    sheHMM_seeWORD)\n",
    "print (\"> sheHMM | she.wav: \",    sheHMM_sheWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock hidden state sequence:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "# Optimal state sequence:\n",
    "# Print the optimal hidden state sequence for the word “rock” using\n",
    "# the HMM representing the word “rock” and paste it into your writeup.\n",
    "\n",
    "rock_state_sequence = rock_HMM.viterbi(rock_phone_likelihoods)\n",
    "print (\"rock hidden state sequence: \", rock_state_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock transition matrix before update:\n",
      " [[0.9 0.1 0.  0.  0.  0. ]\n",
      " [0.  0.9 0.1 0.  0.  0. ]\n",
      " [0.  0.  0.9 0.1 0.  0. ]\n",
      " [0.  0.  0.  0.9 0.1 0. ]\n",
      " [0.  0.  0.  0.  0.9 0.1]\n",
      " [0.  0.  0.  0.  0.  1. ]]\n",
      "rock score before update:  156.7431806240474\n",
      "-------- UPDATE --------\n",
      "rock transition matrix after update:\n",
      " [[0.93333333 0.06666667 0.         0.         0.         0.        ]\n",
      " [0.         0.91666667 0.08333333 0.         0.         0.        ]\n",
      " [0.         0.         0.92857143 0.07142857 0.         0.        ]\n",
      " [0.         0.         0.         0.90909091 0.09090909 0.        ]\n",
      " [0.         0.         0.         0.         0.75       0.25      ]\n",
      " [0.         0.         0.         0.         0.         1.        ]]\n",
      "rock score after update:  157.20291086481836\n"
     ]
    }
   ],
   "source": [
    "# Viterbi Update\n",
    "# Perform a Viterbi update of the transition matrix for the HMM representing\n",
    "# the word “rock,” using the rock.wav file. Next, compute the likelihood of rock.wav with the\n",
    "# updated HMM. What is the new likelihood? Did it go up or down? Print the new transition\n",
    "# matrix (you can exponentiate the log probabilities before you print them to make it more\n",
    "# readable). How did it change?\n",
    "\n",
    "# new rock HMM\n",
    "rock_HMM = MyHMM(phones2indices(['sil', 'r', 'aa', 'cl', 'k', 'sil']), \n",
    "                 np.array([0.5, 0.5, 0.0, 0.0, 0.0, 0.0]), \n",
    "                 np.array([[0.9, 0.1, 0.0, 0.0, 0.0, 0.0],\n",
    "                           [0.0, 0.9, 0.1, 0.0, 0.0, 0.0],\n",
    "                           [0.0, 0.0, 0.9, 0.1, 0.0, 0.0],\n",
    "                           [0.0, 0.0, 0.0, 0.9, 0.1, 0.0],\n",
    "                           [0.0, 0.0, 0.0, 0.0, 0.9, 0.1],\n",
    "                           [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]))\n",
    "print (\"rock transition matrix before update:\\n\", np.exp(rock_HMM.A))\n",
    "\n",
    "# rock score before update\n",
    "rock_score = rock_HMM.forward(rock_phone_likelihoods)\n",
    "print (\"rock score before update: \", rock_score)\n",
    "\n",
    "print (\"-------- UPDATE --------\")\n",
    "\n",
    "# viterbi update\n",
    "rock_A_matrix = rock_HMM.viterbi_transition_update(rock_phone_likelihoods)\n",
    "print (\"rock transition matrix after update:\\n\", np.exp(rock_A_matrix))\n",
    "\n",
    "# rock likelihood after update\n",
    "rock_score = rock_HMM.forward(rock_phone_likelihoods)\n",
    "print (\"rock score after update: \", rock_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2eb717040054f9e1cd6390da57b4c3f6de62338193843f816e8f12a4d5407ba0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
