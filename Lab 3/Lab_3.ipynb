{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phones labels:  ['sil', 's', 'ao', 'l', 'r', 'iy', 'vcl', 'd', 'eh', 'cl', 'p', 'ix', 'z', 'ih', 'sh', 'n', 'v', 'aa', 'y', 'uw', 'w', 'ey', 'dx', 'b', 'ay', 'ng', 'k', 'epi', 'ch', 'dh', 'er', 'en', 'g', 'aw', 'hh', 'ae', 'ow', 't', 'ax', 'm', 'zh', 'ah', 'el', 'f', 'jh', 'uh', 'oy', 'th']\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "from scipy.special import logsumexp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, (1, 5))\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 48)\n",
    "        self.sm = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(-1, 128)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.sm(x)\n",
    "        return x\n",
    "    \n",
    "def load_audio_to_melspec_tensor(wavpath, sample_rate=16000):\n",
    "    window_size = .025\n",
    "    window_stride = 0.01\n",
    "    n_dft = 512\n",
    "    win_length = int(sample_rate * window_size)\n",
    "    hop_length = int(sample_rate * window_stride)\n",
    "    y, sr = librosa.load(wavpath, sr=sample_rate)\n",
    "    y = y - y.mean()\n",
    "    y = np.append(y[0],y[1:]-.97*y[:-1])\n",
    "    # compute mel spectrogram\n",
    "    stft = librosa.stft(y, n_fft=n_dft, hop_length=hop_length,\n",
    "        win_length=win_length, window=scipy.signal.hamming)\n",
    "    spec = np.abs(stft)**2\n",
    "    mel_basis = librosa.filters.mel(sr=sample_rate, n_fft=n_dft, n_mels=40, fmin=20)\n",
    "    melspec = np.dot(mel_basis, spec)\n",
    "    logspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "    logspec = np.transpose(logspec)\n",
    "    logspec_tensor = torch.tensor(logspec)\n",
    "    return logspec_tensor\n",
    "\n",
    "def compute_phone_likelihoods(model, logspec):\n",
    "    likelihood_list = []\n",
    "    with torch.no_grad():\n",
    "        for j in range(6, logspec.size(0) - 5):\n",
    "            inp = logspec[j-5:j+6,:].unsqueeze(0)\n",
    "            output = model(inp) # output will be log probabilities over classes\n",
    "            output = output - math.log(1. / 48) # subtract the logprob of the class priors (assumed to be uniform)\n",
    "            likelihood_list.append(output[0])\n",
    "    likelihoods = torch.transpose(torch.stack(likelihood_list, dim=1), 0, 1).numpy()\n",
    "    return likelihoods\n",
    "\n",
    "model = MyNet()\n",
    "model.load_state_dict(torch.load('lab3_AM.pt'))\n",
    "\n",
    "lab3_data = np.load('lab3_phone_labels.npz')\n",
    "phone_labels = list(lab3_data['phone_labels'])\n",
    "print (\"phones labels: \", phone_labels)\n",
    "\n",
    "def phones2indices(phones):\n",
    "    return [phone_labels.index(p) for p in phones]\n",
    "\n",
    "\n",
    "# fee_HMM = MyHMM(phones2indices(['sil', 'f', 'iy', 'sil']), np.array([0.5, 0.5, 0, 0]), np.array([[.9,.1,0,0],[0,.9,.1,0],[0,0,.9,.1],[0,0,0,1]]))\n",
    "# pea_HMM = MyHMM(phones2indices(['sil', 'p', 'iy', 'sil']), np.array([0.5, 0.5, 0, 0]), np.array([[.9,.1,0,0],[0,.9,.1,0],[0,0,.9,.1],[0,0,0,1]]))\n",
    "# rock_HMM = MyHMM(phones2indices(['sil', 'r', 'aa', 'cl', 'k', 'sil']), np.array([0.5,0.5,0,0,0,0]), np.array([[.9,.1,0,0,0,0],[0,.9,.1,0,0,0],[0,0,.9,.1,0,0],[0,0,0,.9,.1,0],[0,0,0,0,.9,.1],[0,0,0,0,0,1]]))\n",
    "# burt_HMM = MyHMM(phones2indices(['sil', 'b', 'er', 'cl', 't', 'sil']), np.array([0.5,0.5,0,0,0,0]), np.array([[.9,.1,0,0,0,0],[0,.9,.1,0,0,0],[0,0,.9,.1,0,0],[0,0,0,.9,.1,0],[0,0,0,0,.9,.1],[0,0,0,0,0,1]]))\n",
    "# see_HMM = MyHMM(phones2indices(['sil', 's', 'iy', 'sil']), np.array([0.5, 0.5, 0, 0]), np.array([[.9,.1,0,0],[0,.9,.1,0],[0,0,.9,.1],[0,0,0,1]]))\n",
    "# she_HMM = MyHMM(phones2indices(['sil', 'sh', 'iy', 'sil']), np.array([0.5, 0.5, 0, 0]), np.array([[.9,.1,0,0],[0,.9,.1,0],[0,0,.9,.1],[0,0,0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burt_phone_likelihoods.shape:  (100, 48)\n",
      "fee_phone_likelihoods.shape:  (103, 48)\n",
      "pea_phone_likelihoods.shape:  (113, 48)\n",
      "rock_phone_likelihoods.shape:  (81, 48)\n",
      "see_phone_likelihoods.shape:  (96, 48)\n",
      "she_phone_likelihoods.shape:  (107, 48)\n"
     ]
    }
   ],
   "source": [
    "# load in audio files\n",
    "# convert to mel-logspec tensor\n",
    "# compute phone likelihoods for each\n",
    "\n",
    "burt_phone_likelihoods = compute_phone_likelihoods(model, load_audio_to_melspec_tensor(wavpath=\"burt.wav\"))\n",
    "fee_phone_likelihoods = compute_phone_likelihoods(model, load_audio_to_melspec_tensor(wavpath=\"fee.wav\"))\n",
    "pea_phone_likelihoods = compute_phone_likelihoods(model, load_audio_to_melspec_tensor(wavpath=\"pea.wav\"))\n",
    "rock_phone_likelihoods = compute_phone_likelihoods(model, load_audio_to_melspec_tensor(wavpath=\"rock.wav\"))\n",
    "see_phone_likelihoods = compute_phone_likelihoods(model, load_audio_to_melspec_tensor(wavpath=\"see.wav\"))\n",
    "she_phone_likelihoods = compute_phone_likelihoods(model, load_audio_to_melspec_tensor(wavpath=\"she.wav\"))\n",
    "\n",
    "print (\"burt_phone_likelihoods.shape: \", burt_phone_likelihoods.shape)\n",
    "print (\"fee_phone_likelihoods.shape: \", fee_phone_likelihoods.shape)\n",
    "print (\"pea_phone_likelihoods.shape: \", pea_phone_likelihoods.shape)\n",
    "print (\"rock_phone_likelihoods.shape: \", rock_phone_likelihoods.shape)\n",
    "print (\"see_phone_likelihoods.shape: \", see_phone_likelihoods.shape)\n",
    "print (\"she_phone_likelihoods.shape: \", she_phone_likelihoods.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement hidden markov model\n",
    "# A (N x N)= state transition distribution\n",
    "# pi (N x 1)= initial state distribution\n",
    "\n",
    "from math import gamma\n",
    "\n",
    "\n",
    "class MyHMM:\n",
    "    def __init__(self, state_labels, initial_state_distribution, transition_matrix, eps=1e-200):\n",
    "        self.eps = eps\n",
    "        self.total_states = len(state_labels)\n",
    "        # (the product of probabilities becomes addition in log space)\n",
    "        self.pi = np.log(initial_state_distribution + eps)\n",
    "        self.A = np.log(transition_matrix + eps) #A_{ji} is prob of transitioning from state j to state i\n",
    "        self.labels = state_labels # a list where self.labels[j] is the index of the phone label belonging to the jth state\n",
    "        self.N_states = len(self.labels)\n",
    "\n",
    "\n",
    "    def forward(self, state_likelihoods): # state_likelihoods.shape is assumed to be (N_timesteps, 48)\n",
    "        # create B array\n",
    "        N_timesteps = state_likelihoods.shape[0]\n",
    "        self.B = np.zeros((N_timesteps, self.total_states))\n",
    "        i = 0\n",
    "        for state in self.labels:\n",
    "            self.B[:,i] = state_likelihoods[:,state]\n",
    "            i += 1\n",
    "        \n",
    "        # create alpha matrix (N = N timesteps, M = total states)\n",
    "        alpha_matrix = np.zeros((N_timesteps, self.total_states))\n",
    "        \n",
    "        # initialization\n",
    "        t = 0 # time step\n",
    "        i = 0 # state \n",
    "        for i in range (self.total_states):\n",
    "            alpha_matrix[t, i] = self.B[t, i] + self.pi[i]\n",
    "        i += 1\n",
    "\n",
    "        # induction step\n",
    "        for t in range(N_timesteps):\n",
    "            for i in range (self.total_states):\n",
    "                sum = []\n",
    "                j = 0\n",
    "                # get sum\n",
    "                for j in range(self.total_states):\n",
    "                    sum.append(alpha_matrix[t, j] + self.A[j, i])\n",
    "                # multiply values and set alpha\n",
    "                value = logsumexp(sum) + self.B[t, i]\n",
    "                alpha_matrix[t, i] = value\n",
    "\n",
    "        # termination\n",
    "        return alpha_matrix[N_timesteps - 1, self.total_states - 1]\n",
    "    \n",
    "\n",
    "    def viterbi(self, state_likelihoods): # state_likelihoods.shape is assumed to be (N_timesteps, 48)\n",
    "        # create B array\n",
    "        N_timesteps = state_likelihoods.shape[0]\n",
    "        self.B = np.zeros((N_timesteps, self.total_states))\n",
    "        i = 0\n",
    "        for state in self.labels:\n",
    "            self.B[:,i] = state_likelihoods[:,state]\n",
    "            i += 1\n",
    "\n",
    "        # create psi matrix (backtrace)\n",
    "        psi_matrix = np.zeros((N_timesteps, self.total_states))\n",
    "        psi_matrix[0, 0] = 0.0\n",
    "        \n",
    "        # create delta array (N = N timesteps, M = total states)\n",
    "        delta_matrix = np.zeros((N_timesteps, self.total_states))\n",
    "\n",
    "        # initialization\n",
    "        t = 0 # time step\n",
    "        i = 0 # state \n",
    "        for i in range (self.total_states):\n",
    "            delta_matrix[t, i] = self.B[t, i] + self.pi[i]\n",
    "        i += 1\n",
    "\n",
    "        # induction step\n",
    "        for t in range(N_timesteps):\n",
    "            for i in range (self.total_states):\n",
    "                ind_array = []\n",
    "                j = 0\n",
    "                # get induction values to find max\n",
    "                for j in range(self.total_states):\n",
    "                    ind_array.append(delta_matrix[t - 1, j] + self.A[j, i])\n",
    "                # find max, multiply values, and set gamma\n",
    "                value = np.max(ind_array) + self.B[t, i]\n",
    "                delta_matrix[t, i] = value\n",
    "                # set psi backtrace value\n",
    "                psi_matrix[t, i] = np.argmax(ind_array)\n",
    "\n",
    "        # termination\n",
    "        output_path = []\n",
    "        t = N_timesteps - 1\n",
    "        q = int(np.argmax(delta_matrix[t,:]))\n",
    "        output_path.append(q)\n",
    "        t -= 1\n",
    "        while t >= 0:\n",
    "            q = int(psi_matrix[int(t + 1), int(q)])\n",
    "            output_path.append(q)\n",
    "            t -= 1\n",
    "        output_path.reverse()\n",
    "        return output_path\n",
    "    \n",
    "    \n",
    "    def viterbi_transition_update(self, state_likelihoods): # state_likelihoods.shape is assumed to be (N_timesteps, 48)\n",
    "        # compute viterbi algorithm\n",
    "        viterbi_states = self.viterbi(state_likelihoods)\n",
    "\n",
    "        # create temp A matrix using viterbi output\n",
    "        temp_A_matrix = np.zeros((self.total_states, self.total_states))\n",
    "        # number of times model made transition out of state i\n",
    "        num_out_states = np.zeros(self.total_states)\n",
    "        t = 0\n",
    "        for t in range(len(viterbi_states) - 1):\n",
    "            state_i = viterbi_states[t]\n",
    "            state_j = viterbi_states[t + 1]\n",
    "            # number of times transition was made from state i to state j\n",
    "            temp_A_matrix[state_i, state_j] += 1\n",
    "            # number of times model made transition out of state i\n",
    "            num_out_states[state_i] += 1\n",
    "\n",
    "        #print (\"temp A matrix: \", temp_A_matrix)\n",
    "        #print (\"num_out_states: \", num_out_states)\n",
    "\n",
    "        # compute log probabilities for A matrix\n",
    "        for i in range(self.total_states):\n",
    "            for j in range (self.total_states):\n",
    "                numerator = temp_A_matrix[i, j] + self.eps\n",
    "                denominator = num_out_states[i] + self.eps\n",
    "                self.A[i, j] = np.log(numerator / denominator)\n",
    "\n",
    "        #print (\"A log matrix: \", self.A)\n",
    "        #print (\"A matrix: \",np.exp(self.A))\n",
    "        #print (\"viterbi states: \", viterbi_states)\n",
    "        return self.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -0.04255961,   -3.17805383, -463.69507243, -463.69507243],\n",
       "       [-463.65251281,   -0.04445176,   -3.13549422, -463.65251281],\n",
       "       [-463.9510058 , -463.9510058 ,   -0.03278982,   -3.4339872 ],\n",
       "       [-463.84922311, -463.84922311, -463.84922311,    0.        ]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HMM inputs: (state_labels, initial_state_distribution (pi), transition_matrix (A), eps = 1e-200)\n",
    "# HMM.forward inputs: (state_likelihoods (B))\n",
    "# HMM.viterbi inputs: (state_likelihoods (B))\n",
    "# HMM.viterbi_transition_update inputs: (state_likelihoods (B))\n",
    "\n",
    "# remove scientific notation from prints\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# create HMMs for each word\n",
    "burt_HMM = MyHMM(phones2indices(['sil', 'b', 'er', 'cl', 't', 'sil']), # state_labels\n",
    "                 np.array([0.5, 0.5, 0.0, 0.0, 0.0, 0.0]), # initial_state_distribution (pi)\n",
    "                 np.array([[0.9, 0.1, 0.0, 0.0, 0.0, 0.0], # transition_matrix (A)\n",
    "                           [0.0, 0.9, 0.1, 0.0, 0.0, 0.0],\n",
    "                           [0.0, 0.0, 0.9, 0.1, 0.0, 0.0],\n",
    "                           [0.0, 0.0, 0.0, 0.9, 0.1, 0.0],\n",
    "                           [0.0, 0.0, 0.0, 0.0, 0.9, 0.1],\n",
    "                           [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "fee_HMM = MyHMM(phones2indices(['sil', 'f', 'iy', 'sil']), \n",
    "                np.array([0.5, 0.5, 0.0, 0.0]), \n",
    "                np.array([[0.9, 0.1, 0.0, 0.0],\n",
    "                          [0.0, 0.9, 0.1, 0.0],\n",
    "                          [0.0, 0.0, 0.9, 0.1],\n",
    "                          [0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "pea_HMM = MyHMM(phones2indices(['sil', 'p', 'iy', 'sil']),  \n",
    "                np.array([0.5, 0.5, 0.0, 0.0]), \n",
    "                np.array([[0.9, 0.1, 0.0, 0.0],\n",
    "                          [0.0, 0.9, 0.1, 0.0],\n",
    "                          [0.0, 0.0, 0.9, 0.1],\n",
    "                          [0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "rock_HMM = MyHMM(phones2indices(['sil', 'r', 'aa', 'cl', 'k', 'sil']), \n",
    "                 np.array([0.5, 0.5, 0.0, 0.0, 0.0, 0.0]), \n",
    "                 np.array([[0.9, 0.1, 0.0, 0.0, 0.0, 0.0],\n",
    "                           [0.0, 0.9, 0.1, 0.0, 0.0, 0.0],\n",
    "                           [0.0, 0.0, 0.9, 0.1, 0.0, 0.0],\n",
    "                           [0.0, 0.0, 0.0, 0.9, 0.1, 0.0],\n",
    "                           [0.0, 0.0, 0.0, 0.0, 0.9, 0.1],\n",
    "                           [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "see_HMM = MyHMM(phones2indices(['sil', 's', 'iy', 'sil']), \n",
    "                np.array([0.5, 0.5, 0.0, 0.0]), \n",
    "                np.array([[0.9, 0.1, 0.0, 0.0],\n",
    "                          [0.0, 0.9, 0.1, 0.0],\n",
    "                          [0.0, 0.0, 0.9, 0.1],\n",
    "                          [0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "she_HMM = MyHMM(phones2indices(['sil', 'sh', 'iy', 'sil']), \n",
    "                np.array([0.5, 0.5, 0.0, 0.0]), \n",
    "                np.array([[0.9, 0.1, 0.0, 0.0],\n",
    "                          [0.0, 0.9, 0.1, 0.0],\n",
    "                          [0.0, 0.0, 0.9, 0.1],\n",
    "                          [0.0, 0.0, 0.0, 1.0]]))\n",
    "\n",
    "# update HMM transition matricies using respective phone likelihoods\n",
    "burt_HMM.viterbi_transition_update(burt_phone_likelihoods)\n",
    "fee_HMM.viterbi_transition_update(fee_phone_likelihoods)\n",
    "pea_HMM.viterbi_transition_update(pea_phone_likelihoods)\n",
    "rock_HMM.viterbi_transition_update(rock_phone_likelihoods)\n",
    "see_HMM.viterbi_transition_update(see_phone_likelihoods)\n",
    "she_HMM.viterbi_transition_update(she_phone_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burtHMM_burtWORD:\t 210.01143935455625  %\n",
      "burtHMM_feeWORD:\t 173.34636108145781  %\n",
      "burtHMM_peaWORD:\t 2523.851674403464  %\n",
      "burtHMM_rockWORD:\t 65.35098543189584  %\n",
      "burtHMM_seeWORD:\t 1960.1460715153999  %\n",
      "burtHMM_sheWORD:\t 765.5192823290931  %\n"
     ]
    }
   ],
   "source": [
    "# compute log likelihoods for all 6 waveforms with all 6 of the word HMMs\n",
    "# BURT\n",
    "burtHMM_burtWORD = burt_HMM.forward(burt_phone_likelihoods)\n",
    "burtHMM_feeWORD = burt_HMM.forward(fee_phone_likelihoods)\n",
    "burtHMM_peaWORD = burt_HMM.forward(pea_phone_likelihoods)\n",
    "burtHMM_rockWORD = burt_HMM.forward(rock_phone_likelihoods)\n",
    "burtHMM_seeWORD = burt_HMM.forward(see_phone_likelihoods)\n",
    "burtHMM_sheWORD = burt_HMM.forward(she_phone_likelihoods)\n",
    "\n",
    "print (\"burtHMM_burtWORD:\\t\", np.exp(burtHMM_burtWORD) * 100, \" %\")\n",
    "print (\"burtHMM_feeWORD:\\t\", np.exp(burtHMM_feeWORD) * 100, \" %\")\n",
    "print (\"burtHMM_peaWORD:\\t\", np.exp(burtHMM_peaWORD) * 100, \" %\")\n",
    "print (\"burtHMM_rockWORD:\\t\", np.exp(burtHMM_rockWORD) * 100, \" %\")\n",
    "print (\"burtHMM_seeWORD:\\t\", np.exp(burtHMM_seeWORD) * 100, \" %\")\n",
    "print (\"burtHMM_sheWORD:\\t\", np.exp(burtHMM_sheWORD) * 100, \" %\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2eb717040054f9e1cd6390da57b4c3f6de62338193843f816e8f12a4d5407ba0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
